{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41261040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 06:14:16.055651: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752707656.069290   47311 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752707656.072990   47311 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752707656.084074   47311 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752707656.084101   47311 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752707656.084103   47311 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752707656.084104   47311 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-17 06:14:16.087845: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed47393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.11 (main, Dec 11 2024, 16:28:39) [GCC 11.2.0]\n",
      "Operating System: posix\n",
      "Platform: posix.uname_result(sysname='Linux', nodename='DESKTOP-PTROTCH', release='5.15.167.4-microsoft-standard-WSL2', version='#1 SMP Tue Nov 5 00:21:55 UTC 2024', machine='x86_64')\n",
      "GPU Name: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "from typing import *\n",
    "import random as rd\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import optuna\n",
    "import time\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from pynvml import *\n",
    "import re\n",
    "import sys\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "# Get OS information and Python version\n",
    "print(sys.version)\n",
    "print(f\"Operating System: {os.name}\")\n",
    "try:\n",
    "    print(f\"Platform: {os.uname()}\")\n",
    "except:\n",
    "    pass\n",
    "# Check GPU availability\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "gpu_name = tf.config.experimental.get_device_details(gpu_devices[0])['device_name']\n",
    "print(f\"GPU Name: {gpu_name}\")\n",
    "\n",
    "\n",
    "# Checkpointing AKA saveopoint\n",
    "checkpoint_filepath = (\n",
    "   f'RUN/epoch_{{epoch:03d}}-val_f1score{{val_f1score:.4f}}.keras'\n",
    "   )\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "                            filepath=checkpoint_filepath,\n",
    "                            monitor='val_f1score',\n",
    "                            verbose=0,\n",
    "                            save_best_only=False,\n",
    "                            save_weights_only=False,\n",
    "                            save_freq='epoch'\n",
    "                            )\n",
    "\n",
    "# Early Stopping, if validation accuracy does not improve for 20 epochs, then stop.\n",
    "kerasmodel_earlystopping_callbackls = keras.callbacks.EarlyStopping(monitor='val_f1score', patience=20),\n",
    "\n",
    "# WANDB Logger,gets the val accuracy and loss from the model and logs it to WANDB. \n",
    "class simpleWANDBLogger(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "      super(simpleWANDBLogger, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        loggedtrain, loggedval = logs[\"accuracy\"], logs[\"val_accuracy\"]\n",
    "        loggedf1train, loggedf1val = logs[\"f1score\"], logs[\"val_f1score\"]\n",
    "        logged_loss, loggedvalloss = logs[\"loss\"], logs[\"val_loss\"]\n",
    "        learning_rate = self.model.optimizer.learning_rate.numpy()\n",
    "        wandb.log({\n",
    "            \"train_accuracy\": loggedtrain,\n",
    "            \"val_accuracy\": loggedval,\n",
    "            \"train_f1score\": loggedf1train,\n",
    "            \"val_f1score\": loggedf1val,\n",
    "            \"train_loss\": logged_loss,\n",
    "            \"val_loss\": loggedvalloss,\n",
    "            \"learning_rate\": learning_rate\n",
    "        })\n",
    "\n",
    "# Reduce learning rate if validation loss does not improve for 5 epochs, then reduce the learning rate by a factor of 0.5.\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# All callbacks wrapped in a list\n",
    "callbacks=[\n",
    "    model_checkpoint_callback,\n",
    "    kerasmodel_earlystopping_callbackls,\n",
    "    simpleWANDBLogger(),\n",
    "    reduce_lr,\n",
    "]\n",
    "\n",
    "def simplePipeline_CNN(dataset_name: str, batch_size: int = 32, target_sample = 400):\n",
    "    '''\n",
    "    THIS IS JUST FOR TESTING PURPOSES, NOT FOR PRODUCTION USE! :c\n",
    "\n",
    "    A simple pipeline to train a CNN model on a given dataset.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    - dataset_name: \n",
    "        The name of the dataset to be used for training. The dataset should be located in `DATA/!TEMP/<dataset_name>`.\n",
    "        The dataset should be split into train and validation sets in the following structure:\n",
    "        ```\n",
    "        DATA/!TEMP/<dataset_name>\n",
    "            ├── train\n",
    "            │   ├── class1\n",
    "            │   ├── class2\n",
    "            │   └── ...\n",
    "            ├── val\n",
    "            │   ├── class1\n",
    "            │   ├── class2\n",
    "            │   └── ...\n",
    "        ```\n",
    "    - batch_size:\n",
    "        The batch size to be used for training the model. Default is 32.\n",
    "    - target_sample:\n",
    "        The target number of samples per class for balancing the dataset. Default is 400.\n",
    "    '''\n",
    "    dataset_path = os.path.join(\"../DATA/!Temp/\", dataset_name)\n",
    "\n",
    "    # Split the datasets into train and validation\n",
    "    split_train_eval(\n",
    "        dataset_name,\n",
    "        composition= [0.85, 0.15],  # 85% train, 15% validation\n",
    "    )\n",
    "\n",
    "    # Adjust the class balance to have a target number of samples per class\n",
    "    adjustClassBalance(\n",
    "        dataset_name,\n",
    "        target_sample_class=target_sample\n",
    "    )\n",
    "\n",
    "    # Gets generators for all datasets\n",
    "    train_gen, eval_gen = get_train_eval_Generator(\n",
    "        dataset_name,\n",
    "        batch_size= batch_size,\n",
    "    )\n",
    "    test_gen = get_test_generator(batch_size=batch_size)\n",
    "\n",
    "    model = get_model(num_classes= len(train_gen.class_indices))\n",
    "\n",
    "    # Initialize WANDB\n",
    "    wandb.init(project=\"OPTUNA_CNN_NEW\", entity=\"rheyhanfahry\", name=dataset_name)\n",
    "\n",
    "    # Train the model\n",
    "    st = time.time()\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=eval_gen,\n",
    "        epochs=1000,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    et = time.time()\n",
    "    training_time = et - st\n",
    "\n",
    "    # Find the best validation accuracy and load the corresponding model\n",
    "    best_f1score_val = max(history.history['val_f1score'])\n",
    "    fileName = sorted(os.listdir(\"RUN\"))[history.history[\"val_f1score\"].index(best_f1score_val)]\n",
    "    model = keras.models.load_model(f'RUN/{fileName}')\n",
    "\n",
    "    # gets metrics from the model\n",
    "    st = time.time()\n",
    "    result = checkMetrics(model, test_gen, plot_confusion_matrix=False, mode=\"detailed\")\n",
    "    et = time.time()\n",
    "    inference_time = et - st\n",
    "\n",
    "    # Logs how much epoch it took before the training stops\n",
    "    result[\"Epoch\"] = history.history[\"val_f1score\"].index(best_f1score_val)+1\n",
    "\n",
    "    # Logs time taken for training and inference\n",
    "    class_table = wandb.Table(dataframe=pd.DataFrame({\n",
    "        \"Training Time (seconds)\": [training_time],\n",
    "        \"Inference Time (seconds)\": [inference_time]\n",
    "    }))\n",
    "    wandb.log({\n",
    "        \"TIME\" : class_table\n",
    "    })\n",
    "\n",
    "    # log each class metrics to WANDB\n",
    "    log_class = pd.DataFrame(result[\"Class Metrics\"]).T\n",
    "    log_class[[\"True Positives\", \"False Positives\", \"False Negatives\"]] = log_class[[\"True Positives\", \"False Positives\", \"False Negatives\"]].astype(int)\n",
    "    log_class[\"Class\"] = log_class.index\n",
    "    log_class = log_class[[\"Class\", \"True Positives\", \"False Positives\", \"False Negatives\", \"Precision\", \"Recall\", \"F1 Score\"]]\n",
    "    class_table = wandb.Table(dataframe=log_class)\n",
    "    wandb.log({\"each class metrics\": class_table})\n",
    "\n",
    "    # logs overall metrics to WANDB\n",
    "    result.pop(\"Class Metrics\")\n",
    "    log_overall = pd.DataFrame(result, index=[0])\n",
    "    log_overall = log_overall[[\"Epoch\", \"Balanced Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]]\n",
    "    overall_table = wandb.Table(dataframe=log_overall)\n",
    "    wandb.log({\"overall metrics\": overall_table})\n",
    "\n",
    "    # Finish the WANDB run\n",
    "    wandb.finish()\n",
    "\n",
    "    # Clean up temporary directories\n",
    "    shutil.rmtree(\"RUN\", ignore_errors=True)\n",
    "    shutil.rmtree(dataset_path, ignore_errors=True)\n",
    "\n",
    "    return log_overall\n",
    "\n",
    "class getBestHyperparamms_optuna_CNN:\n",
    "    ''''\n",
    "    A class to perform hyperparameter optimization for a CNN model using Optuna.\n",
    "\n",
    "    THE HYPERPARAMETERS TO BE OPTIMIZED ARE:\n",
    "    - num_of_balancing:\n",
    "        The number of samples to balance each class to. This is used in the `adjustClassBalance` function.\n",
    "    - dropout_rate:\n",
    "        The dropout rate to be used in the model. This is used in the `get_model` function.\n",
    "    - batch_size:\n",
    "        The batch size to be used in the model. This is used in the `get_train_eval_Generator` function.\n",
    "    - learning_rate:\n",
    "        The starting learning rate to be used in the model. This is used in the `get_model` function.\n",
    "    - optimizer:\n",
    "        The optimizer to be used in the model. This is used in the `get_model` function.\n",
    "    - num_conv_blocks:\n",
    "        The number of convolutional blocks to be used in the model. This is used in the `get_model` function.\n",
    "    - conv2d_filters:\n",
    "        The number of filters in each convolutional layer. This is used in the `get_model` function.\n",
    "    \n",
    "    HYPERPARAMETERS ARE DEFINED IN THE `objective` FUNCTION.\n",
    "\n",
    "    Pipeline:\n",
    "    - Initialize the class with the number of folds (k) and the directory as a way of autosaving each trial.\n",
    "    - Call the `start` function to begin the optimization process.\n",
    "    - The `objective` function will be called by Optuna for each trial, where a hyperparameter set will be suggested.\n",
    "        - The `stratified_k_fold_cross_validation` function will be used to perform k-fold cross-validation and return the average F1 score for the model where it'll measure the next hyperparameter set to optuna.\n",
    "            - The `stratified_k_fold_split` function will be used to split the dataset into training and validation sets. Where each validation will be unique each fold.\n",
    "            - The `adjustClassBalance` function will be used to balance the classes in the training set.\n",
    "            - the `getBestEpochsandMetrics` function will be used to train the model and get the best epoch and metrics.\n",
    "            - logs the metrics and hyperparameters to WANDB.\n",
    "            - The `autosave` function will be called to save the the metrics of the trial to a CSV file.\n",
    "    - After all trials are completed, the overall metrics will be saved to a CSV file.\n",
    "    - The average metrics will be calculated and saved to a separate CSV file.\n",
    "    '''\n",
    "    def __init__(self, k: int = 4, savedir: str = \"\"):\n",
    "        self.K = k\n",
    "        \n",
    "        # LOGS FOR ALL TRIALS \n",
    "        self.overallMetrics = pd.DataFrame(columns=[\n",
    "            \"fold\", \"num_of_balancing\", \"dropout_rate\", \"batch_size\", \"learning_rate\", \"optimizer\", \"num_conv_blocks\", \n",
    "            \"conv2d_filters\", \"Epoch\", \"Balanced Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
    "        \n",
    "        # Dir of autosave\n",
    "        self.savedir = savedir\n",
    "        self.index = 0\n",
    "        if os.path.exists(self.savedir):\n",
    "            raise FileExistsError(\"Please provide a new directory name, the directory already exists.\")\n",
    "        os.makedirs(self.savedir)\n",
    "\n",
    "    def autosave(self):\n",
    "        '''\n",
    "        Better be safe than sorry.\n",
    "\n",
    "        Saves the overall metrics of the trial to a CSV file in the specified directory.\n",
    "        The CSV file will be named with the current index of the trial.\n",
    "        '''\n",
    "        self.overallMetrics.to_csv(os.path.join(self.savedir, f'{self.index}.csv'), index=False)\n",
    "        self.index +=1\n",
    "\n",
    "    def start(self, trial: int = 50, ):\n",
    "        '''\n",
    "        Starts the hyperparameter optimization process using Optuna.\n",
    "\n",
    "        Parameters\n",
    "        ------------\n",
    "        - trial:\n",
    "            The number of trials to run for hyperparameter optimization. Default is 50.\n",
    "\n",
    "            The trials will be used to find the best hyperparameters for the CNN model.\n",
    "        '''\n",
    "        # Initialized Optuna\n",
    "        storage = optuna.storages.RDBStorage(url=\"sqlite:///optuna_study_CNN.db\")\n",
    "        study = optuna.create_study(direction='maximize', study_name='CNN_Optuna', storage=storage, load_if_exists=True)\n",
    "\n",
    "        # START THE OPTIMIZATION PROCESS\n",
    "        study.optimize(self.objective, n_trials=trial)\n",
    "\n",
    "        # Save the overall metrics to a CSV file\n",
    "        self.overallMetrics.to_csv(\"CNN_overallMetrics.csv\", index=False)\n",
    "        \n",
    "        # Get the average metrics of each fold that has the same hyparameter sets to a CSV file\n",
    "        filters = [i for i in list(self.overallMetrics.columns) if i not in [\"fold\", \"Balanced Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"Epoch\"]]\n",
    "        self.overallMetrics[filters] = self.overallMetrics[filters].astype(str)\n",
    "        avg_metrics = self.overallMetrics.drop(columns=[\"fold\", \"Epoch\"]).groupby(filters).mean().reset_index().sort_values(by=\"F1 Score\", ascending=False)\n",
    "        avg_metrics[\"Epoch\"] = avg_metrics[\"Epoch\"].astype(int)\n",
    "        avg_metrics[\"Balanced Accuracy\"] = avg_metrics[\"Balanced Accuracy\"].round(4)\n",
    "        avg_metrics[\"Precision\"] = avg_metrics[\"Precision\"].round(4)\n",
    "        avg_metrics[\"Recall\"] = avg_metrics[\"Recall\"].round(4)\n",
    "        avg_metrics[\"F1 Score\"] = avg_metrics[\"F1 Score\"].round(4)\n",
    "        avg_metrics.to_csv(\"CNN_averageMetrics.csv\", index=False)\n",
    "\n",
    "    def objective(self, trial):\n",
    "        '''\n",
    "        The objective function for Optuna to optimize the hyperparameters of the CNN model.\n",
    "        '''\n",
    "        self.num_of_balancing = trial.suggest_int('target_sample_class', 250, 500, step=25)\n",
    "        self.dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n",
    "        self.batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])\n",
    "        self.learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n",
    "        self.optimizer = trial.suggest_categorical('optimizer', [\"adam\", \"rmsprop\"])\n",
    "        self.num_conv_blocks = trial.suggest_int('num_conv_blocks', 3, 6)\n",
    "\n",
    "        # ik this is somewhat ugly, but I want to make sure that the filters are increasing in size.\n",
    "        filters_layer1 = trial.suggest_int('filters_layer1', 16, 64, step=16)\n",
    "        filters_layer2 = trial.suggest_int('filters_layer2', filters_layer1, 128, step=16)\n",
    "        filters_layer3 = trial.suggest_int('filters_layer3', filters_layer2, 256, step=32)\n",
    "        filters_layer4 = trial.suggest_int('filters_layer4', filters_layer3, 256, step=32)\n",
    "        filters_layer5 = trial.suggest_int('filters_layer5', filters_layer4, 512, step=32)\n",
    "        filters_layer6 = trial.suggest_int('filters_layer6', filters_layer5, 512, step=32)\n",
    "        self.conv2d_filters=[filters_layer1, filters_layer2, filters_layer3,  filters_layer4, filters_layer5, filters_layer6]\n",
    "\n",
    "        # TEMP DIR name for the dataset. Will be used to create a new dataset for each trial.\n",
    "        self.dataset_name = f\"{self.num_of_balancing}, {self.dropout_rate}, {self.batch_size}, {self.learning_rate}, {self.optimizer}, {self.num_conv_blocks}, {str(self.conv2d_filters)}\"\n",
    "        # Start the K-Fold Cross Validation and get the average F1 score of the validation set.\n",
    "        avg_f1_val = self.stratified_k_fold_cross_validation()\n",
    "        trial.set_user_attr('avg_f1_val', avg_f1_val)   # For logging purposes, just in case!\n",
    "\n",
    "        # Search the next hyperparameter set by focusing on the average F1 score of the validation set\n",
    "        return avg_f1_val\n",
    "\n",
    "    def stratified_k_fold_split(self, dst_name, composition = [0.85, 0.15], seed=rd.randint(0, 100000)):\n",
    "        \"\"\"\n",
    "        Splits the dataset into training and validation sets based on the specified composition.\n",
    "\n",
    "        The dataset is assumed to be located in `DATA/!FINAL/train_val` and will be split into `DATA/!TEMP/<dst_name>/train` and `DATA/!TEMP/<dst_name>/val`.\n",
    "\n",
    "        The split is done in a stratified manner. THIS MEANS EACH VALIDATION SET WILL BE UNIQUE EACH FOLD. \n",
    "\n",
    "        Parameters\n",
    "        ------------\n",
    "        - dst_name:\n",
    "            The name of the destination directory where the split dataset will be saved.\n",
    "        - composition:\n",
    "            A list of two floats representing the proportion of training and validation data.\n",
    "        \"\"\"\n",
    "        assert sum(composition) == 1, \"Composition must sum to 1\"\n",
    "        \n",
    "        # Split dataset into train and val equally on each class\n",
    "        for class_name in tqdm(os.listdir(f'../DATA/!FINAL/train_val'), desc=\"Splitting data into train and eval\"):\n",
    "            class_path = os.path.join(f'../DATA/!FINAL/train_val', class_name)\n",
    "\n",
    "            # Create paths for train and val directories\n",
    "            for split in [\"train\", \"val\"]:\n",
    "                os.makedirs(os.path.join(\"../DATA/!TEMP/\", dst_name, split, class_name), exist_ok=True)\n",
    "\n",
    "            # Split the images into train and eval sets\n",
    "            eval_target = int(len(os.listdir(class_path)) * composition[1])\n",
    "            list_of_images = os.listdir(class_path)\n",
    "\n",
    "            # Shuffle the images and get unique image for evaluation each fold by excluding blacklisted images\n",
    "            rd.seed(seed)\n",
    "            rd.shuffle(list_of_images)\n",
    "            eval_image = [i for i in list_of_images if i not in self.blacklist[class_name]][:eval_target]\n",
    "            train_image = [i for i in list_of_images if i not in eval_image]\n",
    "\n",
    "            # Copy images to the respective directories\n",
    "            for image in train_image:\n",
    "                shutil.copy(os.path.join(class_path, image), os.path.join(\"../DATA/!TEMP\", dst_name, \"train\", class_name, image))\n",
    "            for image in eval_image:\n",
    "                shutil.copy(os.path.join(class_path, image), os.path.join(\"../DATA/!TEMP\", dst_name, \"val\", class_name, image))\n",
    "            \n",
    "            # Update the blacklist for the next fold\n",
    "            self.blacklist[class_name].extend(eval_image)\n",
    "    \n",
    "    def stratified_k_fold_cross_validation(self):\n",
    "        '''\n",
    "        Performs K-Fold Cross Validation on the dataset.\n",
    "\n",
    "        Also \n",
    "        '''\n",
    "\n",
    "        # The blacklit dictionary is used to keep track of the images that have been used in the validation set so it won't be used again in the next fold!\n",
    "        self.blacklist = {\"Darna_trima\": [], \"Parasa_lepida\": [], \"Setora_nitens\": [], \"Setothosea_asigna\": []}\n",
    "\n",
    "        f1_fold = []\n",
    "\n",
    "        for i in tqdm(range(self.K), desc=\"K-Fold Cross Validation\"):\n",
    "            # Create a unique temporary directory for each fold\n",
    "            fold_name = f\"{i}_fold_{self.dataset_name}\"\n",
    "            dataset_path = os.path.join(\"../DATA/!TEMP\", fold_name)\n",
    "\n",
    "            # Create the directory for the fold where it composes the train and validation sets\n",
    "            self.stratified_k_fold_split(fold_name, composition=[0.85, 0.15])\n",
    "            # Adjust the class balance for the training set\n",
    "            adjustClassBalance(fold_name, target_sample_class=self.num_of_balancing)\n",
    "\n",
    "            # Get the train and validation generators\n",
    "            self.train_generator, self.validation_generator = get_train_eval_Generator(fold_name, batch_size=self.batch_size, target_size=(224, 224))\n",
    "\n",
    "            # Initialize WANDB\n",
    "            wandb.init(project=\"OPTUNA_CNN_NEW\", entity=\"rheyhanfahry\", name=fold_name)\n",
    "\n",
    "            # Train and get the best epochs and its metrics \n",
    "            result = self.getBestEpochsandMetrics()\n",
    "\n",
    "            # Clean up the temporary directories\n",
    "            shutil.rmtree(dataset_path, ignore_errors=True)\n",
    "\n",
    "            # logs the hyperparameters used\n",
    "            result[\"num_of_balancing\"] = self.num_of_balancing\n",
    "            result[\"dropout_rate\"] = self.dropout_rate\n",
    "            result[\"batch_size\"] = self.batch_size\n",
    "            result[\"learning_rate\"] = self.learning_rate\n",
    "            result[\"optimizer\"] = self.optimizer\n",
    "            result[\"num_conv_blocks\"] = self.num_conv_blocks\n",
    "            result[\"conv2d_filters\"] = str(self.conv2d_filters)\n",
    "            result[\"fold\"] = i + 1\n",
    "            self.overallMetrics = pd.concat([self.overallMetrics, result], ignore_index=True)\n",
    "\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            self.autosave()\n",
    "\n",
    "            f1_fold.append(result[\"F1 Score\"].values[0])\n",
    "\n",
    "        return  np.mean(f1_fold)\n",
    "\n",
    "    def getBestEpochsandMetrics(self):\n",
    "        \"\"\"\n",
    "        Trains the model and gets the best epoch and its metrics.\n",
    "\n",
    "        This function trains the model using the training generator and validation generator.\n",
    "\n",
    "        It uses the callbacks defined earlier to save the best model and log the metrics to WANDB\n",
    "        \n",
    "        After training, it evaluates the model on the validation generator and logs the metrics to WANDB\n",
    "\n",
    "        and returns the overall metrics as a DataFrame.\n",
    "        \"\"\"\n",
    "        # Try except block to catch any errors during training and evaluation. \n",
    "        try:\n",
    "            model = get_model(num_classes=len(self.train_generator.class_indices),\n",
    "                            conv2d_filters=self.conv2d_filters,\n",
    "                            num_conv_blocks=self.num_conv_blocks,\n",
    "                            dropout_rate=self.dropout_rate,\n",
    "                            optimizer=self.optimizer,\n",
    "                            learning_rate=self.learning_rate)\n",
    "            \n",
    "            # Compute class weights to handle class imbalance\n",
    "            class_weights = compute_class_weight('balanced', classes=np.unique(self.train_generator.classes), y=self.train_generator.classes)\n",
    "            class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "            # Start training the model\n",
    "            st = time.time()\n",
    "            history = model.fit(\n",
    "                self.train_generator,\n",
    "                validation_data=self.validation_generator,\n",
    "                epochs=1000,\n",
    "                callbacks=[callbacks],\n",
    "                verbose=1,\n",
    "                class_weight=class_weight_dict,)\n",
    "            et = time.time()\n",
    "            training_time = et - st\n",
    "\n",
    "            # Find the best validation accuracy and load the corresponding model\n",
    "            best_f1score_val = max(history.history['val_f1score'])\n",
    "            fileName = sorted(os.listdir(\"RUN\"))[history.history[\"val_f1score\"].index(best_f1score_val)]\n",
    "            model = keras.models.load_model(f'RUN/{fileName}')\n",
    "\n",
    "            # gets metrics from the model\n",
    "            st = time.time()\n",
    "            result = checkMetrics(model, self.validation_generator, plot_confusion_matrix=False, mode=\"detailed\")\n",
    "            et = time.time()\n",
    "            inference_time = et - st\n",
    "            # Logs how much epoch it took before the training stops\n",
    "            result[\"Epoch\"] = history.history[\"val_f1score\"].index(best_f1score_val)+1\n",
    "\n",
    "            # Logs time taken for training and inference\n",
    "            class_table = wandb.Table(dataframe=pd.DataFrame({\n",
    "                \"Training Time (seconds)\": [training_time],\n",
    "                \"Inference Time (seconds)\": [inference_time]\n",
    "            }))\n",
    "            wandb.log({\"TIME\" : class_table})\n",
    "\n",
    "            # Logs each class metrics\n",
    "            log_class = pd.DataFrame(result[\"Class Metrics\"]).T\n",
    "            log_class[[\"True Positives\", \"False Positives\", \"False Negatives\"]] = log_class[[\"True Positives\", \"False Positives\", \"False Negatives\"]].astype(int)\n",
    "            log_class[\"Class\"] = log_class.index\n",
    "            log_class = log_class[[\"Class\", \"True Positives\", \"False Positives\", \"False Negatives\", \"Precision\", \"Recall\", \"F1 Score\"]]\n",
    "            class_table = wandb.Table(dataframe=log_class)\n",
    "            wandb.log({\"each class metrics\": class_table})\n",
    "\n",
    "            # Logs overall metrics\n",
    "            result.pop(\"Class Metrics\")\n",
    "            log_overall = pd.DataFrame(result, index=[0])\n",
    "            log_overall = log_overall[[\"Epoch\", \"Balanced Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]]\n",
    "            overall_table = wandb.Table(dataframe=log_overall)\n",
    "            wandb.log({\"overall metrics\": overall_table})\n",
    "\n",
    "            # used_vram, total_vram = get_vram_usage()\n",
    "            \n",
    "            del model\n",
    "            # if (used_vram / total_vram) > 0.7:\n",
    "            #     gc.collect()\n",
    "            #     keras.backend.clear_session()\n",
    "            # Clean up temporary directories\n",
    "            shutil.rmtree(\"RUN\", ignore_errors=True)\n",
    "\n",
    "            # Finish the WANDB run\n",
    "            wandb.finish()\n",
    "        \n",
    "        except:\n",
    "            # If there is an error, send an email and raise an exception so it'll stop!.\n",
    "            send_email(\n",
    "                text=f\"Error in fold {self.index} with parameters: num_of_balancing={self.num_of_balancing}, dropout_rate={self.dropout_rate}, batch_size={self.batch_size}, learning_rate={self.learning_rate}, optimizer={self.optimizer}, num_conv_blocks={self.num_conv_blocks}, conv2d_filters={self.conv2d_filters}\")\n",
    "            raise Exception(f\"FOUND ERROR, PLEASE RESTART!\")\n",
    "\n",
    "        return log_overall\n",
    "\n",
    "class get_test_score(getBestHyperparamms_optuna_CNN):\n",
    "    \"\"\"\n",
    "    A class to get the test score of a CNN model using the best hyperparameters found by Optuna.\n",
    "    This class inherits from `getBestHyperparamms_optuna_CNN` and uses the same hyperparameter optimization process.\n",
    "\n",
    "    Pipeline:\n",
    "    - Initialize the class with the number of folds (k) and the directory as a way of autosaving each trial.\n",
    "    - Call the `start` function to begin the optimization process.\n",
    "    - The `start` function will read the best hyperparameters from the `CNN_averageMetrics.csv` file.\n",
    "    - For each set of hyperparameters, it will perform K-Fold Cross Validation to get the test score.\n",
    "    - The `stratified_k_fold_split` function will be used to split the dataset into training and validation sets.\n",
    "    - The `adjustClassBalance` function will be used to balance the classes in the training set.\n",
    "    - The `RESULT_getBestEpochsandMetrics` function will be used to train the model and get the best epoch based on val sets.\n",
    "    - Gets the metrics of test set and logs the metrics and hyperparameters to WANDB.\n",
    "    - The `autosave` function will be called to save the the metrics of the trial to a CSV file.\n",
    "    - After all trials are completed, the overall metrics will be saved to a CSV file.\n",
    "    - The average metrics will be calculated and saved to a separate CSV file.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n=10, k=4):\n",
    "\n",
    "        # Validate input parameters\n",
    "        assert n > 0, \"n must be greater than 0\"\n",
    "        assert k > 0, \"k must be greater than 0\"\n",
    "\n",
    "        self.n = n\n",
    "        self.K = k\n",
    "\n",
    "        # the logs for all trials\n",
    "        self.overallMetrics = pd.DataFrame(columns=[\n",
    "            \"fold\", \"num_of_balancing\", \"dropout_rate\", \"batch_size\", \"learning_rate\", \"optimizer\", \"num_conv_blocks\", \n",
    "            \"conv2d_filters\", \"Epoch\", \"Balanced Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
    "        \n",
    "        # Directory for autosaving. Hope this syntax will only be run once.\n",
    "        self.savedir = \"TESTRESULTS_CHECKPOINTS\"\n",
    "        self.index = 0\n",
    "        if os .path.exists(self.savedir):\n",
    "            raise FileExistsError(\"Please provide a new directory name, the directory already exists.\")\n",
    "        os.makedirs(self.savedir)\n",
    "\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Starts the process of getting the test score of the CNN model using the best hyperparameters found by Optuna on the previous syntax.\n",
    "        This function reads the best hyperparameters from the `CNN_averageMetrics.csv` file and performs K-Fold Cross Validation to get the test score.\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(\"CNN_averageMetrics.csv\")\n",
    "\n",
    "        # Uses the first n rows of the DataFrame to get the best hyperparameters.\n",
    "        for params in df.loc[:self.n-1].values:\n",
    "            # Unpack the parameters\n",
    "            self.num_of_balancing = params[0]\n",
    "            self.dropout_rate = params[1]\n",
    "            self.batch_size = params[2]\n",
    "            self.learning_rate = params[3]\n",
    "            self.optimizer = params[4]\n",
    "            self.num_conv_blocks = params[5]\n",
    "            self.conv2d_filters = []\n",
    "            filters = re.findall(r'\\d+', params[6]) # This is a shit method, but it works. So I will use it! :D\n",
    "            for i in range(self.num_conv_blocks):\n",
    "                self.conv2d_filters.append(int(filters[i]))\n",
    "\n",
    "            self.test_generator = get_test_generator(batch_size=self.batch_size)\n",
    "\n",
    "            self.blacklist = {\"Darna_trima\": [], \"Parasa_lepida\": [], \"Setora_nitens\": [], \"Setothosea_asigna\": []}\n",
    "\n",
    "            # The name of the run with this hyperparameter sets, will be used for naming temporary dirs\n",
    "            self.name = f\"RESULT {self.num_of_balancing}_{self.dropout_rate}_{self.batch_size}_{self.learning_rate}_{self.optimizer}_{self.num_conv_blocks}_{str(self.conv2d_filters)}\"\n",
    "\n",
    "            # Starts of K-fold cross validation\n",
    "            for i in tqdm(range(self.K), desc=\"K-Fold Cross Validation for Test Score\"):\n",
    "                fold_name = f\"{i}_fold_{self.name}\"\n",
    "\n",
    "                # Create train and validation dataset\n",
    "                self.stratified_k_fold_split(fold_name, composition=[0.85, 0.15])\n",
    "                # Adjust the class balance for the training set\n",
    "                adjustClassBalance(fold_name, target_sample_class=self.num_of_balancing)\n",
    "\n",
    "                self.train_generator, self.validation_generator = get_train_eval_Generator(fold_name, batch_size=self.batch_size, target_size=(224, 224))\n",
    "\n",
    "                # Initialize WANDB for this fold\n",
    "                wandb.init(project=\"OPTUNA_CNN_NEW\", entity=\"rheyhanfahry\", name=fold_name)\n",
    "\n",
    "                # Train the model and get the best epoch based on validation sets\n",
    "                result = self.RESULT_getBestEpochsandMetrics()\n",
    "\n",
    "                # Clean up the temporary directories\n",
    "                dataset_path = os.path.join(\"../DATA/!TEMP\", fold_name)\n",
    "                shutil.rmtree(dataset_path, ignore_errors=True)\n",
    "\n",
    "                # logs the hyperparameters used\n",
    "                result[\"num_of_balancing\"] = self.num_of_balancing\n",
    "                result[\"dropout_rate\"] = self.dropout_rate\n",
    "                result[\"batch_size\"] = self.batch_size\n",
    "                result[\"learning_rate\"] = self.learning_rate\n",
    "                result[\"optimizer\"] = self.optimizer\n",
    "                result[\"num_conv_blocks\"] = self.num_conv_blocks\n",
    "                result[\"conv2d_filters\"] = str(self.conv2d_filters)\n",
    "                result[\"fold\"] = i + 1\n",
    "                self.overallMetrics = pd.concat([self.overallMetrics, result], ignore_index=True)\n",
    "\n",
    "                clear_output(wait=True)\n",
    "\n",
    "                self.autosave()\n",
    "\n",
    "        # Save the overall metrics to a CSV file\n",
    "        self.overallMetrics.to_csv(\"CNN_TEST_RESULTS_OVERALL.csv\", index=False)\n",
    "\n",
    "        # Get the average metrics of each fold that has the same hyperparameter sets to a CSV file\n",
    "        filters = [i for i in list(self.overallMetrics.columns) if i not in [\"fold\", \"Balanced Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"Epoch\"]]\n",
    "        self.overallMetrics[filters] = self.overallMetrics[filters].astype(str)\n",
    "        avg_metrics = self.overallMetrics.drop(columns=[\"fold\", \"Epoch\"]).groupby(filters).mean().reset_index().sort_values(by=\"F1 Score\", ascending=False)\n",
    "        avg_metrics[\"Balanced Accuracy\"] = avg_metrics[\"Balanced Accuracy\"].round(4)\n",
    "        avg_metrics[\"Precision\"] = avg_metrics[\"Precision\"].round(4)\n",
    "        avg_metrics[\"Recall\"] = avg_metrics[\"Recall\"].round(4)\n",
    "        avg_metrics[\"F1 Score\"] = avg_metrics[\"F1 Score\"].round(4)\n",
    "        avg_metrics.sort_values(by=\"F1 Score\", ascending=False)\n",
    "        avg_metrics.to_csv(\"CNN_TEST_RESULTS.csv\", index=False)\n",
    "\n",
    "    def RESULT_getBestEpochsandMetrics(self):\n",
    "        '''\n",
    "        Trains the model and gets the best epoch based from validation sets.\n",
    "\n",
    "        Then evaluates the model on the test set and logs the metrics to WANDB.\n",
    "        '''\n",
    "        try:\n",
    "            model = get_model(num_classes=len(self.train_generator.class_indices),\n",
    "                            conv2d_filters=self.conv2d_filters,\n",
    "                            num_conv_blocks=self.num_conv_blocks,\n",
    "                            dropout_rate=self.dropout_rate,\n",
    "                            optimizer=self.optimizer,\n",
    "                            learning_rate=self.learning_rate)\n",
    "            # Compute class weights to handle class imbalance\n",
    "            class_weights = compute_class_weight('balanced', classes=np.unique(self.train_generator.classes), y=self.train_generator.classes)\n",
    "            class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "            # Start training the model\n",
    "            st = time.time()\n",
    "            history = model.fit(\n",
    "                self.train_generator,\n",
    "                validation_data=self.validation_generator,\n",
    "                epochs=1000,\n",
    "                callbacks=[callbacks],\n",
    "                verbose=1,\n",
    "                class_weight=class_weight_dict)\n",
    "            et = time.time()\n",
    "            training_time = et - st\n",
    "\n",
    "            # Find the best validation f1_accuracy and load the corresponding model\n",
    "            best_f1score_val = max(history.history['val_f1score'])\n",
    "            fileName = sorted(os.listdir(\"RUN\"))[history.history[\"val_f1score\"].index(best_f1score_val)]\n",
    "            model = keras.models.load_model(f'RUN/{fileName}')\n",
    "\n",
    "            # gets test sets metrics from the model\n",
    "            st = time.time()\n",
    "            result = checkMetrics(model, self.test_generator, plot_confusion_matrix=False, mode=\"detailed\")\n",
    "            et = time.time()\n",
    "            inference_time = et - st\n",
    "\n",
    "            # Logs how much epoch it took before the training stops\n",
    "            result[\"Epoch\"] = history.history[\"val_f1score\"].index(best_f1score_val)+1\n",
    "\n",
    "            # Logs time taken for training and inference\n",
    "            class_table = wandb.Table(dataframe=pd.DataFrame({\n",
    "                \"Training Time (seconds)\": [training_time],\n",
    "                \"Inference Time (seconds)\": [inference_time]\n",
    "            }))\n",
    "            wandb.log({\"TIME\" : class_table})\n",
    "\n",
    "            # each class metrics\n",
    "            log_class = pd.DataFrame(result[\"Class Metrics\"]).T\n",
    "            log_class[[\"True Positives\", \"False Positives\", \"False Negatives\"]] = log_class[[\"True Positives\", \"False Positives\", \"False Negatives\"]].astype(int)\n",
    "            log_class[\"Class\"] = log_class.index\n",
    "            log_class = log_class[[\"Class\", \"True Positives\", \"False Positives\", \"False Negatives\", \"Precision\", \"Recall\", \"F1 Score\"]]\n",
    "            class_table = wandb.Table(dataframe=log_class)\n",
    "            wandb.log({\"each class metrics\": class_table})\n",
    "\n",
    "            # overall metrics\n",
    "            result.pop(\"Class Metrics\")\n",
    "            log_overall = pd.DataFrame(result, index=[0])\n",
    "            log_overall = log_overall[[\"Epoch\", \"Balanced Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]]\n",
    "            overall_table = wandb.Table(dataframe=log_overall)\n",
    "            wandb.log({\"overall metrics\": overall_table})\n",
    "\n",
    "            # Remove the temp RUN directory\n",
    "            shutil.rmtree(\"RUN\", ignore_errors=True)\n",
    "\n",
    "            # Finish the WANDB run\n",
    "            wandb.finish()\n",
    "        \n",
    "        except:\n",
    "            # If there is an error, send an email and raise an exception so it'll stop!\n",
    "            send_email(\n",
    "                text=f\"Error in TEST RESULT fold {self.index} with parameters: num_of_balancing={self.num_of_balancing}, dropout_rate={self.dropout_rate}, batch_size={self.batch_size}, learning_rate={self.learning_rate}, optimizer={self.optimizer}, num_conv_blocks={self.num_conv_blocks}, conv2d_filters={self.conv2d_filters}\")\n",
    "            raise Exception(f\"FOUND ERROR, PLEASE RESTART!\")\n",
    "        \n",
    "        return log_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a86b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If error occurs primarly VRAM issues, restart the notebook and re run the code!\n",
    "a = getBestHyperparamms_optuna_CNN(k=4, savedir=\"CNN_12\")\n",
    "a.start(trial=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0fb962dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "# This code collects the results from all CNN checkpoints and creates all the metrics in a single CSV file while also creating an average metrics CSV file.\n",
    "\n",
    "temp = pd.DataFrame()\n",
    "CNN_checkpoint_dirs = [i for i in os.listdir(\"CNN_RUN\") if i.startswith(\"CNN\") and os.path.isdir(os.path.join(\"CNN_RUN\", i))]\n",
    "\n",
    "for DIR in CNN_checkpoint_dirs:\n",
    "    latest_csv_index = ((sorted([int(re.search(r\"\\d+\", i)[0]) for i in os.listdir(os.path.join(\"CNN_RUN\", DIR)) if not i.startswith(\"ERROR\")])[-1]))\n",
    "    latest_csv_path = os.path.join(\"CNN_RUN\", DIR, f'{latest_csv_index}.csv')\n",
    "    table = pd.read_csv(latest_csv_path)\n",
    "    temp = pd.concat([temp, table], ignore_index=True)\n",
    "\n",
    "# Just in case if it fails to converge. Remove them bcz bad accuracies.    \n",
    "temp = temp[temp['Epoch'] > 10]\n",
    "filters = [i for i in list(temp.columns) if i not in [\"fold\", \"Balanced Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"Epoch\"]]\n",
    "temp[filters] = temp[filters].astype(str)\n",
    "# Remove Config with less than 4 folds\n",
    "unique_configs = temp.groupby(filters).filter(lambda x: x['fold'].nunique() < 4)\n",
    "temp = temp[~temp.index.isin(unique_configs.index)]\n",
    "temp = temp.iloc[: 400]\n",
    "\n",
    "\n",
    "temp = temp.reset_index(drop=True)\n",
    "temp.to_csv(\"CNN_overallMetrics.csv\", index=False)\n",
    "\n",
    "temp[\"trial\"] = [j+1 for j in range(100) for i in range(4)]\n",
    "avg_metrics = temp.drop(columns=[\"fold\", \"Epoch\"]).groupby(filters).mean().reset_index().sort_values(by=\"trial\", ascending=True)\n",
    "\n",
    "avg_metrics[\"Balanced Accuracy\"] = avg_metrics[\"Balanced Accuracy\"].round(4)\n",
    "avg_metrics[\"Precision\"] = avg_metrics[\"Precision\"].round(4)\n",
    "avg_metrics[\"Recall\"] = avg_metrics[\"Recall\"].round(4)\n",
    "avg_metrics[\"F1 Score\"] = avg_metrics[\"F1 Score\"].round(4)\n",
    "avg_metrics.to_csv(\"UNSORTED_AVERAGE_CNN_TUNING.csv\", index=False)\n",
    "\n",
    "avg_metrics = avg_metrics.sort_values(by=\"F1 Score\", ascending=False)\n",
    "\n",
    "avg_metrics.to_csv(\"CNN_averageMetrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c5bcc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_of_balancing</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>num_conv_blocks</th>\n",
       "      <th>conv2d_filters</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>0.2096187982506599</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0001320860146001</td>\n",
       "      <td>adam</td>\n",
       "      <td>6</td>\n",
       "      <td>[64, 64, 224, 256, 352, 448]</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.9212</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.9237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250</td>\n",
       "      <td>0.2106727953816496</td>\n",
       "      <td>8</td>\n",
       "      <td>7.845771933593588e-05</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>4</td>\n",
       "      <td>[64, 96, 192, 192, 256, 320]</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.8636</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.8697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250</td>\n",
       "      <td>0.238016296900337</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0007062700618815</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>4</td>\n",
       "      <td>[48, 128, 160, 192, 320, 416]</td>\n",
       "      <td>0.9206</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.9206</td>\n",
       "      <td>0.9105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>0.2556817738581848</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0005022153460409</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>6</td>\n",
       "      <td>[32, 32, 192, 224, 320, 480]</td>\n",
       "      <td>0.9266</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.9266</td>\n",
       "      <td>0.9204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>250</td>\n",
       "      <td>0.2699098581523874</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0001238216661377</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>6</td>\n",
       "      <td>[16, 96, 160, 160, 192, 224]</td>\n",
       "      <td>0.9353</td>\n",
       "      <td>0.9217</td>\n",
       "      <td>0.9353</td>\n",
       "      <td>0.9265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>500</td>\n",
       "      <td>0.3316622070043765</td>\n",
       "      <td>8</td>\n",
       "      <td>8.995545138853484e-05</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>5</td>\n",
       "      <td>[48, 112, 112, 112, 240, 272]</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.9408</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.9414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>500</td>\n",
       "      <td>0.4107515906788274</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0004081973850847</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>5</td>\n",
       "      <td>[64, 96, 192, 256, 256, 320]</td>\n",
       "      <td>0.9504</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.9504</td>\n",
       "      <td>0.9530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>500</td>\n",
       "      <td>0.4178215658946088</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0004476545411722</td>\n",
       "      <td>adam</td>\n",
       "      <td>4</td>\n",
       "      <td>[64, 112, 240, 240, 336, 368]</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>0.9172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>500</td>\n",
       "      <td>0.428617501730154</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0003490759393051</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>6</td>\n",
       "      <td>[48, 80, 144, 208, 464, 464]</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.9551</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.9532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>500</td>\n",
       "      <td>0.4752486000744957</td>\n",
       "      <td>32</td>\n",
       "      <td>1.2922080532412252e-05</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>6</td>\n",
       "      <td>[32, 96, 224, 224, 224, 256]</td>\n",
       "      <td>0.7785</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>0.7785</td>\n",
       "      <td>0.7518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_of_balancing        dropout_rate batch_size           learning_rate  \\\n",
       "1                250  0.2096187982506599         16      0.0001320860146001   \n",
       "2                250  0.2106727953816496          8   7.845771933593588e-05   \n",
       "3                250   0.238016296900337         16      0.0007062700618815   \n",
       "4                250  0.2556817738581848          8      0.0005022153460409   \n",
       "5                250  0.2699098581523874         16      0.0001238216661377   \n",
       "..               ...                 ...        ...                     ...   \n",
       "96               500  0.3316622070043765          8   8.995545138853484e-05   \n",
       "97               500  0.4107515906788274         32      0.0004081973850847   \n",
       "98               500  0.4178215658946088         16      0.0004476545411722   \n",
       "99               500   0.428617501730154         16      0.0003490759393051   \n",
       "100              500  0.4752486000744957         32  1.2922080532412252e-05   \n",
       "\n",
       "    optimizer num_conv_blocks                 conv2d_filters  \\\n",
       "1        adam               6   [64, 64, 224, 256, 352, 448]   \n",
       "2     rmsprop               4   [64, 96, 192, 192, 256, 320]   \n",
       "3     rmsprop               4  [48, 128, 160, 192, 320, 416]   \n",
       "4     rmsprop               6   [32, 32, 192, 224, 320, 480]   \n",
       "5     rmsprop               6   [16, 96, 160, 160, 192, 224]   \n",
       "..        ...             ...                            ...   \n",
       "96    rmsprop               5  [48, 112, 112, 112, 240, 272]   \n",
       "97    rmsprop               5   [64, 96, 192, 256, 256, 320]   \n",
       "98       adam               4  [64, 112, 240, 240, 336, 368]   \n",
       "99    rmsprop               6   [48, 80, 144, 208, 464, 464]   \n",
       "100   rmsprop               6   [32, 96, 224, 224, 224, 256]   \n",
       "\n",
       "     Balanced Accuracy  Precision  Recall  F1 Score  \n",
       "1               0.9298     0.9212  0.9298    0.9237  \n",
       "2               0.8818     0.8636  0.8818    0.8697  \n",
       "3               0.9206     0.9044  0.9206    0.9105  \n",
       "4               0.9266     0.9172  0.9266    0.9204  \n",
       "5               0.9353     0.9217  0.9353    0.9265  \n",
       "..                 ...        ...     ...       ...  \n",
       "96              0.9436     0.9408  0.9436    0.9414  \n",
       "97              0.9504     0.9566  0.9504    0.9530  \n",
       "98              0.9231     0.9136  0.9232    0.9172  \n",
       "99              0.9525     0.9551  0.9525    0.9532  \n",
       "100             0.7785     0.7506  0.7785    0.7518  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1d4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_test_score(n=10, k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ed958",
   "metadata": {},
   "source": [
    "## DEBUG, SINGLE RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f403ba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"../DATA/!Temp/\", ignore_errors=True)\n",
    "shutil.rmtree(\"RUN\", ignore_errors=True)\n",
    "shutil.rmtree(\"wandb\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b55c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplePipeline_CNN(\n",
    "#     dataset_name=\"dataset_1\",\n",
    "#     batch_size=32,\n",
    "#     target_sample=400\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
